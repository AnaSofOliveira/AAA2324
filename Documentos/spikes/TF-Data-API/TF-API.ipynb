{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF data records and dataset creation  + TF Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo simples\n",
    "#### O que é a classe \"dataset\" do TF\n",
    "## ver https://www.tensorflow.org/guide/data\n",
    "### Criação deste tipo de dados com tf.data.Dataset.from_tensor_slices() ou só \"from_tensor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar as bibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from time import time\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#para usar GPU\n",
    "gp=tf.config.list_physical_devices('GPU')\n",
    "print(gp)\n",
    "if len(gp)!=0:\n",
    "    tf.config.experimental.set_memory_growth(gp[0],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criar gerador a partir de tensor (range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "a=tf.range(10)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X=tf.range(10)\n",
    "print(X)\n",
    "DT=tf.data.Dataset.from_tensor_slices(X)\n",
    "# or DT=tf.dataDatase.range(10)\n",
    "print(DT)\n",
    "for i in DT:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 5 5 8 9]\n",
      " [6 7 3 0 5]\n",
      " [3 2 4 2 3]], shape=(3, 5), dtype=int32)\n",
      "<TensorSliceDataset shapes: (5,), types: tf.int32>\n",
      "tf.Tensor([4 5 5 8 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor([6 7 3 0 5], shape=(5,), dtype=int32)\n",
      "tf.Tensor([3 2 4 2 3], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#tensor com 3 elementos por slice\n",
    "X=tf.convert_to_tensor(rd.randint(0,10,(3,5),dtype='int32'))\n",
    "print(X)\n",
    "DT=tf.data.Dataset.from_tensor_slices(X)\n",
    "print(DT)\n",
    "for i in DT:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usar comando $\\texttt{take}$ para ver só uns quantos itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X=tf.range(10)\n",
    "print(X)\n",
    "DT=tf.data.Dataset.from_tensor_slices(X)\n",
    "print(DT)\n",
    "for i in DT.take(3):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X=tf.range(10)\n",
    "print(X)\n",
    "DT=tf.data.Dataset.from_tensor_slices(X)\n",
    "for i in range(4):\n",
    "    for j in DT.take(3):\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset as a Python iterator - using the $\\texttt{next()}$ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fd580d8dda0>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#python iterators\n",
    "X=tf.range(10)\n",
    "print(X)\n",
    "DT=tf.data.Dataset.from_tensor_slices(X)\n",
    "print(DT)\n",
    "it=iter(DT)\n",
    "print(it)\n",
    "print(next(it))\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X=tf.range(10)\n",
    "print(X)\n",
    "DT=tf.data.Dataset.from_tensor_slices(X)\n",
    "print(DT)\n",
    "it=iter(DT)\n",
    "# Error when N>10\n",
    "N=10\n",
    "for i in range(N):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other dataset creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because I could not stop for Death,\n",
      "He kindly stopped for me;\n",
      "The carriage held but just ourselves\n",
      "And Immortality.\n",
      "\n",
      "I'm nobody! Who are you?\n",
      "Are you nobody, too?\n",
      "Then there's a pair of us - don't tell!\n",
      "They'd banish us, you know.\n",
      "How dreary to be somebody!\n",
      "How public, like a frog\n",
      "To tell your name the livelong day\n",
      "To an admiring bog!\n",
      "\n",
      "Because I could not stop for Death,\n",
      "He kindly stopped for me;\n",
      "The carriage held but just ourselves\n",
      "And Immortality.\n",
      "I'm nobody! Who are you?\n",
      "Are you nobody, too?\n",
      "Then there's a pair of us - don't tell!\n",
      "They'd banish us, you know.\n",
      "How dreary to be somebody!\n",
      "How public, like a frog\n",
      "To tell your name the livelong day\n",
      "To an admiring bog!\n"
     ]
    }
   ],
   "source": [
    "#processing lines from files\n",
    "f1=open('file1.txt')\n",
    "print(str(f1.read()))\n",
    "f1.close()\n",
    "f2=open('file2.txt')\n",
    "print(str(f2.read()))\n",
    "f2.close()\n",
    "\n",
    "DT= tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])\n",
    "#DT= tf.data.TextLineDataset([\"CaliforniaHousing.csv\"])\n",
    "for l in DT:\n",
    "    print(l.numpy().decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O código anterior pode ser feito encadeando comandos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********1st****************\n",
      "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int64)\n",
      "tf.Tensor([6 7 8 9 0 1], shape=(6,), dtype=int64)\n",
      "tf.Tensor([2 3 4 5 6 7], shape=(6,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n",
      "**********2nd****************\n",
      "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int64)\n",
      "tf.Tensor([6 7 8 9], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int64)\n",
      "tf.Tensor([6 7 8 9], shape=(4,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT=tf.data.Dataset.range(10).repeat(2).batch(6)\n",
    "print('**********1st****************')\n",
    "[print(i) for i in DT]\n",
    "    \n",
    "    \n",
    "print('**********2nd****************')\n",
    "DT=tf.data.Dataset.range(10).batch(6).repeat(2)\n",
    "[print(i) for i in DT]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use shuffle before batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********1st****************\n",
      "tf.Tensor([0 1 2 3 4 0], shape=(6,), dtype=int64)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 0 1], shape=(6,), dtype=int64)\n",
      "**********2nd****************\n",
      "tf.Tensor([1 4 0 2 2 3], shape=(6,), dtype=int64)\n",
      "tf.Tensor([0 0 2 1 3 4], shape=(6,), dtype=int64)\n",
      "tf.Tensor([4 3 1], shape=(3,), dtype=int64)\n",
      "**********3rd****************\n",
      "tf.Tensor([0 3 4 2 1 0], shape=(6,), dtype=int64)\n",
      "tf.Tensor([4 2 3 1 3 2], shape=(6,), dtype=int64)\n",
      "tf.Tensor([0 1 4], shape=(3,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT=tf.data.Dataset.range(5).repeat(3).batch(6).shuffle(buffer_size=5)\n",
    "print('**********1st****************')\n",
    "[print(i) for i in DT]\n",
    "    \n",
    "    \n",
    "DT=tf.data.Dataset.range(5).repeat(3).shuffle(buffer_size=5).batch(6)\n",
    "print('**********2nd****************')\n",
    "[print(i) for i in DT]\n",
    "\n",
    "DT=tf.data.Dataset.range(5).shuffle(buffer_size=5).repeat(3).batch(6)\n",
    "print('**********3rd****************')\n",
    "[print(i) for i in DT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9 0 1], shape=(12,), dtype=int64)\n",
      "tf.Tensor([2 3 4 5 6 7 8 9 0 1 2 3], shape=(12,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batchS=12\n",
    "DT=tf.data.Dataset.range(10).repeat(3).batch(batchS).shuffle(buffer_size=10)\n",
    "for i in DT:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 2 8 1 7 9 2 0 0 4 6 3], shape=(12,), dtype=int64)\n",
      "tf.Tensor([1 0 9 3 7 6 7 8 3 4 6 8], shape=(12,), dtype=int64)\n",
      "tf.Tensor([4 1 5 9 5 2], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#baralhar (necessário recomeçar)\n",
    "DT=tf.data.Dataset.range(10).repeat(3).shuffle(buffer_size=10,seed=42).batch(batchS)\n",
    "#DT=DT.shuffle(buffer_size=10,seed=42).batch(batchS)\n",
    "for i in DT:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com .repeat() o gerador não para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 9 6 4 7 1 2 8 3 0], shape=(10,), dtype=int64)\n",
      "tf.Tensor([3 7 6 5 8 4 0 1 9 2], shape=(10,), dtype=int64)\n",
      "tf.Tensor([2 8 9 6 0 4 1 3 5 7], shape=(10,), dtype=int64)\n",
      "tf.Tensor([6 9 0 5 3 2 4 1 8 7], shape=(10,), dtype=int64)\n",
      "tf.Tensor([9 5 1 8 7 4 3 0 2 6], shape=(10,), dtype=int64)\n",
      "tf.Tensor([4 7 8 1 9 0 6 5 3 2], shape=(10,), dtype=int64)\n",
      "tf.Tensor([2 1 6 8 3 0 7 4 5 9], shape=(10,), dtype=int64)\n",
      "tf.Tensor([2 7 9 1 8 5 6 3 0 4], shape=(10,), dtype=int64)\n",
      "tf.Tensor([7 9 0 6 2 3 5 1 8 4], shape=(10,), dtype=int64)\n",
      "tf.Tensor([0 9 2 5 6 3 7 8 1 4], shape=(10,), dtype=int64)\n",
      "tf.Tensor([1 4 0 6 9 5 3 8 2 7], shape=(10,), dtype=int64)\n",
      "tf.Tensor([1 4 2 6 7 8 3 5 9 0], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "DT=tf.data.Dataset.range(10).shuffle(buffer_size=10,seed=42).batch(batchS).repeat()\n",
    "\n",
    "for i,x in enumerate(DT):\n",
    "    print(x)\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aceder aos elementos de DT:\n",
    "#### Notar que DT são só 3 tensores - take(n) com n>3 não altera resultado\n",
    "#### Mas pode-se chamar várias vezes e dá tensores diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 3 4 5 6 7 8 9 0 1 2 3], shape=(12,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9 0 1], shape=(12,), dtype=int64)\n",
      "-\n",
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int64)\n",
      "tf.Tensor([2 3 4 5 6 7 8 9 0 1 2 3], shape=(12,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9 0 1], shape=(12,), dtype=int64)\n",
      "-\n",
      "tf.Tensor([2 3 4 5 6 7 8 9 0 1 2 3], shape=(12,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9 0 1], shape=(12,), dtype=int64)\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "    for r in DT.take(5):\n",
    "        print(r)\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criar e ler um simples dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar um gerador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar gerador de três elementos\n",
    "def arrayInt():\n",
    "    return rd.randint(-2**15,2**15,size=4,dtype='int16')\n",
    "\n",
    "def matrixUint():\n",
    "    return rd.randint(0,255,size=(3,3),dtype='uint8')\n",
    "\n",
    "def arrayFloat():\n",
    "    return rd. randn(5).astype(np.float32)\n",
    "\n",
    "def generator():\n",
    "    #deitar continuamente\n",
    "    while(True):\n",
    "        a=arrayInt()\n",
    "        M=matrixUint()\n",
    "        f=arrayFloat()\n",
    "        \n",
    "        yield a,M,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9664  1814 16082 -5422]\n",
      "[[174 121 225]\n",
      " [183 189   9]\n",
      " [ 69 175  16]]\n",
      "[-1.0999719   0.11372941  1.5592335  -0.40443957 -0.93626505]\n",
      "[31978 -6440 20259 15913]\n",
      "[[177 191 165]\n",
      " [107  60 182]\n",
      " [ 97  80  73]]\n",
      "[-1.219581    0.6939774  -0.5321984  -0.55153555 -0.7087945 ]\n",
      "[ 14957  31681  27183 -30740]\n",
      "[[208 156 161]\n",
      " [ 16 160  13]\n",
      " [103  32 102]]\n",
      "[0.75400746 0.4059997  0.21547839 0.3382673  0.35364875]\n",
      "[21245 -3219 -3164 25968]\n",
      "[[204 154  27]\n",
      " [110  56 212]\n",
      " [ 17  47   2]]\n",
      "[-0.77188593 -0.5023383  -0.02088019  0.3830908   1.7038862 ]\n",
      "[ 13650  -9724   8775 -15946]\n",
      "[[124 216 235]\n",
      " [161 142  62]\n",
      " [129  32 179]]\n",
      "[ 0.46829972  1.9050341  -0.7707365  -0.31116116 -0.04753039]\n",
      "[-19367  30382  25698  28629]\n",
      "[[150  40  19]\n",
      " [ 12 168 254]\n",
      " [243 135  69]]\n",
      "[-0.5030424   0.3905247  -0.32169467  0.3690189   0.42744833]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for a,M,f in generator():\n",
    "    c+=1\n",
    "    print(a)\n",
    "    print(M)\n",
    "    print(f)\n",
    "    if c>5:\n",
    "        break\n",
    "\n",
    "print(c)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-27762   4119 -21466   9569], shape=(4,), dtype=int16)\n",
      "tf.Tensor(\n",
      "[[181 114 159]\n",
      " [ 87 103 125]\n",
      " [ 98  80 147]], shape=(3, 3), dtype=uint8)\n",
      "tf.Tensor([-0.13291968  0.67417353  0.2437165  -1.2371067  -1.1164429 ], shape=(5,), dtype=float32)\n",
      "tf.Tensor([-15943 -12276  -9545  -9070], shape=(4,), dtype=int16)\n",
      "tf.Tensor(\n",
      "[[220 248 192]\n",
      " [106  62 251]\n",
      " [164  23 186]], shape=(3, 3), dtype=uint8)\n",
      "tf.Tensor([ 0.02280253  0.8596388   1.1581112   0.5963715  -0.1857946 ], shape=(5,), dtype=float32)\n",
      "tf.Tensor([25169  -502 14755 -9987], shape=(4,), dtype=int16)\n",
      "tf.Tensor(\n",
      "[[ 98   8   5]\n",
      " [105 132 102]\n",
      " [196 151  56]], shape=(3, 3), dtype=uint8)\n",
      "tf.Tensor([ 1.1551803  -0.65935916 -1.921149   -0.6476706  -0.03043949], shape=(5,), dtype=float32)\n",
      "tf.Tensor([ 11082 -20151 -25111 -20970], shape=(4,), dtype=int16)\n",
      "tf.Tensor(\n",
      "[[ 25 190 173]\n",
      " [175  75 124]\n",
      " [ 47  27 223]], shape=(3, 3), dtype=uint8)\n",
      "tf.Tensor([ 1.0355753   0.09367475  0.26215106 -0.24967682 -0.01290622], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "DT=tf.data.Dataset.from_generator(generator,(tf.int16,tf.uint8,tf.float32),((4,),(3,3),(5,)))\n",
    "DT2=DT.batch(1)\n",
    "for a,M,f in DT.take(4):\n",
    "    print(a)\n",
    "    print(M)\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations\n",
    "### map(), filter() and apply() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "\n",
      "\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n"
     ]
    }
   ],
   "source": [
    "#DT= tf.data.Dataset.range(10).shuffle(10,reshuffle_each_iteration=False,seed=42).repeat(3).batch(5)\n",
    "DT= tf.data.Dataset.range(10).repeat(3).batch(5)\n",
    "for l in DT:\n",
    "    print(l.numpy())\n",
    "DT=DT.map(lambda x :x*(x%2))\n",
    "print('\\n')\n",
    "for l in DT:\n",
    "    print(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "a:\n",
      "\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "False\n",
      "\n",
      "b:\n",
      "\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "[0 1 0 3 0]\n",
      "[5 0 7 0 9]\n",
      "\n",
      "c:\n",
      "\n",
      "True\n",
      "[0 1 2 3 4]\n",
      "True\n",
      "[5 6 7 8 9]\n",
      "True\n",
      "[0 1 2 3 4]\n",
      "True\n",
      "[5 6 7 8 9]\n",
      "True\n",
      "[0 1 2 3 4]\n",
      "True\n",
      "[5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "def odd_a(x):\n",
    "    print(tf.executing_eagerly())\n",
    "    return x*(x%2)\n",
    "\n",
    "def odd_b(x):\n",
    "    print(tf.executing_eagerly())\n",
    "    x=tf.math.multiply(x,tf.math.floormod(x,2))\n",
    "    return x\n",
    "\n",
    "#@tf.function\n",
    "def odd_c(x):\n",
    "    print(tf.executing_eagerly())\n",
    "    x=x*(np.remainder(x,2))\n",
    "    #return tf.Tensor(x) #dá erro!\n",
    "    return tf.convert_to_tensor(x) #já não dá!\n",
    "\n",
    "@tf.function\n",
    "def wrapper(x):\n",
    "    #x=odd_a(x)\n",
    "\n",
    "    tf.py_function(func=odd_a,inp=[x],Tout=[tf.int64]) \n",
    "    #tf.function(odd_b)\n",
    "    return x\n",
    "\n",
    "DT= tf.data.Dataset.range(10).repeat(3).batch(5)\n",
    "#for l in DT:\n",
    "#    print(l.numpy())\n",
    "\n",
    "DTa=DT.map(odd_a)\n",
    "print('\\na:\\n')\n",
    "for l in DTa:\n",
    "    print(l.numpy())\n",
    "\n",
    "DTb=DT.map(odd_b)\n",
    "print('\\nb:\\n')\n",
    "for l in DTb:\n",
    "    print(l.numpy())\n",
    "\n",
    "DTc=DT.map(wrapper) #bad! -> com odd_a ou odd_b não se queixa mas não tira valores pares!!!\n",
    "print('\\nc:\\n')\n",
    "for l in DTc:\n",
    "    print(l.numpy())\n",
    "\n",
    "#x=tf.Tensor([0,0,0,0,0],dtype='int64')\n",
    "#x=tf.Variable([0,0,0,0,0],dtype='int64')\n",
    "#x=np.array([0,0,0,0,0],dtype='int64')\n",
    "#x=tf.compat.v1.placeholder(tf.int64)\n",
    "#odd_d=tf.py_function(func=odd_d,inp=[x],Tout=[tf.int64])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i in DTc:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    <ipython-input-35-5332fcf02362>:20 odd_E  *\n        x=tf.convert_to_tensor(x*(np.remainder(x,2)))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:870 __array__  **\n        \" a NumPy call, which is not supported\".format(self.name))\n\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5332fcf02362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0modd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0modd_E\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mDTa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0modd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0met\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1860\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1861\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4983\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4984\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4985\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4986\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4987\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4218\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4219\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3149\u001b[0m     \"\"\"\n\u001b[1;32m   3150\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3151\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4194\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4195\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4123\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4125\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4126\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    <ipython-input-35-5332fcf02362>:20 odd_E  *\n        x=tf.convert_to_tensor(x*(np.remainder(x,2)))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:870 __array__  **\n        \" a NumPy call, which is not supported\".format(self.name))\n\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "def odd_A(x):\n",
    "    x=x*(x%2)\n",
    "    return x\n",
    "\n",
    "def odd_B(x):\n",
    "    x=tf.math.multiply(tf.math.floormod(x,2),x)\n",
    "    return x\n",
    "@tf.function\n",
    "def odd_C(x):\n",
    "    return tf.math.multiply(tf.math.floormod(x,2),x)\n",
    "\n",
    "\n",
    "#Assim não dá.  TF->Numpy proibido\n",
    "def odd_D(x):\n",
    "    x=x*(np.remainder(x,2))\n",
    "    return x\n",
    "\n",
    "#Assim já dá!!! NÃO: voltou a não dar!?!?!\n",
    "def odd_E(x):\n",
    "    x=tf.convert_to_tensor(x*(np.remainder(x,2)))\n",
    "    return x\n",
    "\n",
    "DT= tf.data.Dataset.range(10).repeat(3).batch(5)\n",
    "\n",
    "for l in DT:\n",
    "    print(l.numpy())\n",
    "\n",
    "odd=odd_E\n",
    "st=time()\n",
    "DTa=DT.map(odd)\n",
    "et=time()\n",
    "print(et-st)\n",
    "print('\\na:\\n')\n",
    "for l in DTa:\n",
    "    print(l.numpy())\n",
    "\n",
    "\n",
    "#Assim não dá - algo a haver com eager mode...\n",
    "#DTb=DT.map(tf.py_function(func=odd_C,inp=[tf.int32],Tout=[tf.int32]))\n",
    "#print('\\nb:\\n')\n",
    "#for l in DTb:\n",
    "#    print(l.numpy())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
